{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f947897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d003231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset. it's in parquet format\n",
    "df = pd.read_parquet(\"data/fhv_tripdata_2021-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734669b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of records in Jan 2021 FHV data {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the duration of each trip\n",
    "df[\"duration\"] = df.dropOff_datetime - df.pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the average trip time?\n",
    "trip_duration = np.mean(df.duration).round(2)\n",
    "print(f\"Average trip duration in January is {trip_duration} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9366192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    # load the dataset\n",
    "    \n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        df.pickup_datetime = pd.to_datetime(df.pickup_datetime)\n",
    "        df.dropOff_datetime = pd.to_datetime(df.dropOff_datetime)\n",
    "    else:\n",
    "        df = pd.read_parquet(filename)\n",
    "    \n",
    "    # create a trip duration column\n",
    "        \n",
    "    df[\"duration\"] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    \n",
    "    # fill in the missing values with -1\n",
    "    \n",
    "    df[\"PUlocationID\"].fillna(-1, inplace=True)\n",
    "    df[\"DOlocationID\"].fillna(-1, inplace=True)\n",
    "    \n",
    "    # PulocationID and DOlocation are categorical data\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and validatation data set. January is for training, February is for validation\n",
    "\n",
    "train = read_dataframe(\"data/fhv_tripdata_2021-01.parquet\")\n",
    "val = read_dataframe(\"data/fhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the first five rows of our train data\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc89362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the percentage of the missing value in pick up location ID?\n",
    "\n",
    "missing_values = np.around(train[\"PUlocationID\"].value_counts(normalize=True), 3)\n",
    "print(f\"Fraction of missing values for pickup location ID: {missing_values[0] * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a760809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of categorical variables using dictvectorizer\n",
    "\n",
    "features = [\"PUlocationID\", \"DOlocationID\"]\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = train[features].to_dict(orient=\"records\")\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = val[features].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of the train and validation data after one hot encoding\n",
    "print(f\"The train dataset has {X_train.shape[0]} rows and {X_train.shape[1]} columns\")\n",
    "print(f\"The validation dataset has {X_val.shape[0]} rows and {X_val.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a74224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our features and target \n",
    "\n",
    "target = 'duration'\n",
    "y_train = train[target].values\n",
    "y_val = val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f62ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, fit and predict using LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr.predict(X_train)\n",
    "\n",
    "train_rmse = mean_squared_error(train_pred, y_train, squared=False)\n",
    "print(f\"Train rmse: {train_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ca354",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_pred, label='prediction')\n",
    "sns.distplot(y_train, label='actual')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e62842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the performance of our model on validation data\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "val_rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(f\"Val rmse: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lin_reg.bin', 'wb') as f:\n",
    "    pickle.dump((dv, lr), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
